{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2287183f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import chi2, mutual_info_classif, SelectKBest, f_classif\n",
    "from sklearn.model_selection import cross_val_score \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "\n",
    "#Load data from csv file\n",
    "data = pd.read_csv(\"data1NormWithColNamesRowNames.csv\")\n",
    "data.head(10) \n",
    "\n",
    "data.set_index(\"Unnamed: 0\", inplace = True)\n",
    "data.index.name = None\n",
    "\n",
    "X = data.iloc[:, data.columns != 'assigned_cluster'].values\n",
    "#X=data.iloc[:,0:4915]\n",
    "X = np.absolute(X)\n",
    "\n",
    "y = data.iloc[:,data.columns == 'assigned_cluster'].values.ravel()\n",
    "\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86f7aac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=xgb.XGBClassifier(use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df04aaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10; 1/1] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.2, max_depth=10, min_child_weight=7\n",
      "[14:30:43] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10; 1/1] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.2, max_depth=10, min_child_weight=7;, score=0.984 total time= 2.5min\n",
      "[CV 8/10; 1/1] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.3, max_depth=8, min_child_weight=3\n",
      "[14:33:53] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10; 1/1] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.3, max_depth=8, min_child_weight=3;, score=0.969 total time= 2.2min\n",
      "[CV 4/10; 1/1] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.15, max_depth=4, min_child_weight=3\n",
      "[14:36:33] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10; 1/1] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.15, max_depth=4, min_child_weight=3;, score=0.995 total time= 2.8min\n",
      "[CV 6/10; 1/1] START colsample_bytree=0.3, gamma=0.3, learning_rate=0.15, max_depth=6, min_child_weight=5\n",
      "[14:40:01] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10; 1/1] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.15, max_depth=6, min_child_weight=5;, score=0.959 total time= 1.8min\n",
      "[CV 9/10; 1/1] START colsample_bytree=0.3, gamma=0.3, learning_rate=0.15, max_depth=6, min_child_weight=5\n",
      "[14:41:51] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10; 1/1] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.15, max_depth=6, min_child_weight=5;, score=0.974 total time=  28.8s\n",
      "[CV 3/10; 1/1] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=5, min_child_weight=3\n",
      "[14:42:20] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10; 1/1] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=5, min_child_weight=3;, score=0.969 total time= 1.9min\n",
      "[CV 10/10; 1/1] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=5, min_child_weight=3\n",
      "[14:44:17] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10; 1/1] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=5, min_child_weight=3;, score=0.953 total time=  30.2s\n",
      "[CV 3/10; 1/1] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.25, max_depth=6, min_child_weight=3\n",
      "[14:44:49] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10; 1/1] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.25, max_depth=6, min_child_weight=3;, score=0.974 total time= 3.6min\n",
      "[CV 10/10; 1/1] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.25, max_depth=6, min_child_weight=3\n",
      "[14:48:25] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10; 1/1] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.25, max_depth=6, min_child_weight=3;, score=0.953 total time=  59.5s\n",
      "[CV 2/10; 1/1] START colsample_bytree=0.7, gamma=0.3, learning_rate=0.15, max_depth=4, min_child_weight=3\n",
      "[14:49:25] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10; 1/1] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.15, max_depth=4, min_child_weight=3;, score=0.974 total time= 3.8min\n",
      "[CV 5/10; 1/1] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.2, max_depth=10, min_child_weight=7\n",
      "[14:30:43] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10; 1/1] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.2, max_depth=10, min_child_weight=7;, score=0.974 total time= 2.5min\n",
      "[CV 3/10; 1/1] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.3, max_depth=8, min_child_weight=3\n",
      "[14:33:52] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10; 1/1] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.3, max_depth=8, min_child_weight=3;, score=0.969 total time= 2.1min\n",
      "[CV 10/10; 1/1] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.3, max_depth=8, min_child_weight=3\n",
      "[14:35:58] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10; 1/1] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.3, max_depth=8, min_child_weight=3;, score=0.953 total time=  33.7s\n",
      "[CV 5/10; 1/1] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.15, max_depth=4, min_child_weight=3\n",
      "[14:36:33] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10; 1/1] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.15, max_depth=4, min_child_weight=3;, score=0.979 total time= 2.8min\n",
      "[CV 8/10; 1/1] START colsample_bytree=0.3, gamma=0.3, learning_rate=0.15, max_depth=6, min_child_weight=5\n",
      "[14:40:01] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10; 1/1] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.15, max_depth=6, min_child_weight=5;, score=0.974 total time= 1.9min\n",
      "[CV 1/10; 1/1] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=5, min_child_weight=3\n",
      "[14:42:20] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10; 1/1] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=5, min_child_weight=3;, score=0.984 total time= 2.0min\n",
      "[CV 5/10; 1/1] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.25, max_depth=6, min_child_weight=3\n",
      "[14:44:49] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10; 1/1] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.25, max_depth=6, min_child_weight=3;, score=0.969 total time= 3.6min\n",
      "[CV 1/10; 1/1] START colsample_bytree=0.7, gamma=0.3, learning_rate=0.15, max_depth=4, min_child_weight=3\n",
      "[14:49:25] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10; 1/1] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.15, max_depth=4, min_child_weight=3;, score=0.979 total time= 3.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10; 1/1] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.2, max_depth=10, min_child_weight=7\n",
      "[14:30:43] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10; 1/1] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.2, max_depth=10, min_child_weight=7;, score=0.984 total time= 2.6min\n",
      "[CV 6/10; 1/1] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.3, max_depth=8, min_child_weight=3\n",
      "[14:33:52] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10; 1/1] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.3, max_depth=8, min_child_weight=3;, score=0.964 total time= 2.1min\n",
      "[CV 9/10; 1/1] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.3, max_depth=8, min_child_weight=3\n",
      "[14:35:57] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10; 1/1] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.3, max_depth=8, min_child_weight=3;, score=0.974 total time=  35.5s\n",
      "[CV 3/10; 1/1] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.15, max_depth=4, min_child_weight=3\n",
      "[14:36:33] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10; 1/1] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.15, max_depth=4, min_child_weight=3;, score=0.969 total time= 2.8min\n",
      "[CV 1/10; 1/1] START colsample_bytree=0.3, gamma=0.3, learning_rate=0.15, max_depth=6, min_child_weight=5\n",
      "[14:40:01] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10; 1/1] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.15, max_depth=6, min_child_weight=5;, score=0.979 total time= 1.9min\n",
      "[CV 7/10; 1/1] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=5, min_child_weight=3\n",
      "[14:42:20] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10; 1/1] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=5, min_child_weight=3;, score=0.969 total time= 2.0min\n",
      "[CV 1/10; 1/1] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.25, max_depth=6, min_child_weight=3\n",
      "[14:44:49] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10; 1/1] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.25, max_depth=6, min_child_weight=3;, score=0.979 total time= 3.7min\n",
      "[CV 7/10; 1/1] START colsample_bytree=0.7, gamma=0.3, learning_rate=0.15, max_depth=4, min_child_weight=3\n",
      "[14:49:25] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10; 1/1] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.15, max_depth=4, min_child_weight=3;, score=0.959 total time= 3.8min\n",
      "[CV 8/10; 1/1] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.2, max_depth=10, min_child_weight=7\n",
      "[14:30:43] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10; 1/1] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.2, max_depth=10, min_child_weight=7;, score=0.974 total time= 2.5min\n",
      "[CV 5/10; 1/1] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.3, max_depth=8, min_child_weight=3\n",
      "[14:33:52] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10; 1/1] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.3, max_depth=8, min_child_weight=3;, score=0.979 total time= 2.2min\n",
      "[CV 8/10; 1/1] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.15, max_depth=4, min_child_weight=3\n",
      "[14:36:33] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10; 1/1] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.15, max_depth=4, min_child_weight=3;, score=0.979 total time= 2.8min\n",
      "[CV 5/10; 1/1] START colsample_bytree=0.3, gamma=0.3, learning_rate=0.15, max_depth=6, min_child_weight=5\n",
      "[14:40:01] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10; 1/1] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.15, max_depth=6, min_child_weight=5;, score=0.984 total time= 1.9min\n",
      "[CV 2/10; 1/1] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=5, min_child_weight=3\n",
      "[14:42:20] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10; 1/1] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=5, min_child_weight=3;, score=0.974 total time= 2.0min\n",
      "[CV 7/10; 1/1] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.25, max_depth=6, min_child_weight=3\n",
      "[14:44:49] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10; 1/1] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.25, max_depth=6, min_child_weight=3;, score=0.948 total time= 3.7min\n",
      "[CV 5/10; 1/1] START colsample_bytree=0.7, gamma=0.3, learning_rate=0.15, max_depth=4, min_child_weight=3\n",
      "[14:49:25] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10; 1/1] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.15, max_depth=4, min_child_weight=3;, score=0.969 total time= 3.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10; 1/1] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.2, max_depth=10, min_child_weight=7\n",
      "[14:30:42] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10; 1/1] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.2, max_depth=10, min_child_weight=7;, score=0.959 total time= 2.5min\n",
      "[CV 9/10; 1/1] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.2, max_depth=10, min_child_weight=7\n",
      "[14:33:10] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10; 1/1] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.2, max_depth=10, min_child_weight=7;, score=0.964 total time=  41.5s\n",
      "[CV 2/10; 1/1] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.3, max_depth=8, min_child_weight=3\n",
      "[14:33:52] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10; 1/1] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.3, max_depth=8, min_child_weight=3;, score=0.974 total time= 2.2min\n",
      "[CV 1/10; 1/1] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.15, max_depth=4, min_child_weight=3\n",
      "[14:36:33] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10; 1/1] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.15, max_depth=4, min_child_weight=3;, score=0.990 total time= 2.8min\n",
      "[CV 7/10; 1/1] START colsample_bytree=0.3, gamma=0.3, learning_rate=0.15, max_depth=6, min_child_weight=5\n",
      "[14:40:01] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10; 1/1] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.15, max_depth=6, min_child_weight=5;, score=0.959 total time= 1.9min\n",
      "[CV 8/10; 1/1] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=5, min_child_weight=3\n",
      "[14:42:21] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10; 1/1] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=5, min_child_weight=3;, score=0.979 total time= 2.0min\n",
      "[CV 4/10; 1/1] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.25, max_depth=6, min_child_weight=3\n",
      "[14:44:50] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10; 1/1] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.25, max_depth=6, min_child_weight=3;, score=0.979 total time= 3.7min\n",
      "[CV 4/10; 1/1] START colsample_bytree=0.7, gamma=0.3, learning_rate=0.15, max_depth=4, min_child_weight=3\n",
      "[14:49:25] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10; 1/1] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.15, max_depth=4, min_child_weight=3;, score=0.984 total time= 3.8min\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10; 1/1] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.2, max_depth=10, min_child_weight=7\n",
      "[14:30:43] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10; 1/1] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.2, max_depth=10, min_child_weight=7;, score=0.974 total time= 2.5min\n",
      "[CV 10/10; 1/1] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.2, max_depth=10, min_child_weight=7\n",
      "[14:33:11] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10; 1/1] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.2, max_depth=10, min_child_weight=7;, score=0.953 total time=  40.4s\n",
      "[CV 4/10; 1/1] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.3, max_depth=8, min_child_weight=3\n",
      "[14:33:53] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10; 1/1] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.3, max_depth=8, min_child_weight=3;, score=0.984 total time= 2.2min\n",
      "[CV 6/10; 1/1] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.15, max_depth=4, min_child_weight=3\n",
      "[14:36:33] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10; 1/1] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.15, max_depth=4, min_child_weight=3;, score=0.964 total time= 2.8min\n",
      "[CV 9/10; 1/1] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.15, max_depth=4, min_child_weight=3\n",
      "[14:39:18] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10; 1/1] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.15, max_depth=4, min_child_weight=3;, score=0.974 total time=  42.0s\n",
      "[CV 3/10; 1/1] START colsample_bytree=0.3, gamma=0.3, learning_rate=0.15, max_depth=6, min_child_weight=5\n",
      "[14:40:01] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10; 1/1] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.15, max_depth=6, min_child_weight=5;, score=0.974 total time= 1.9min\n",
      "[CV 10/10; 1/1] START colsample_bytree=0.3, gamma=0.3, learning_rate=0.15, max_depth=6, min_child_weight=5\n",
      "[14:41:51] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10; 1/1] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.15, max_depth=6, min_child_weight=5;, score=0.959 total time=  27.6s\n",
      "[CV 4/10; 1/1] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=5, min_child_weight=3\n",
      "[14:42:20] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10; 1/1] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=5, min_child_weight=3;, score=0.974 total time= 2.0min\n",
      "[CV 8/10; 1/1] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.25, max_depth=6, min_child_weight=3\n",
      "[14:44:50] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10; 1/1] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.25, max_depth=6, min_child_weight=3;, score=0.984 total time= 3.7min\n",
      "[CV 8/10; 1/1] START colsample_bytree=0.7, gamma=0.3, learning_rate=0.15, max_depth=4, min_child_weight=3\n",
      "[14:49:25] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10; 1/1] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.15, max_depth=4, min_child_weight=3;, score=0.990 total time= 3.7min\n",
      "[CV 1/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=1\n",
      "[15:05:34] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=1;, score=0.979 total time= 2.8min\n",
      "[CV 9/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=1\n",
      "[15:08:25] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=1;, score=0.964 total time=  44.9s\n",
      "[CV 7/10; 1/1] START colsample_bytree=0.3, gamma=0.4, learning_rate=0.25, max_depth=15, min_child_weight=3\n",
      "[15:09:11] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10; 1/1] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.25, max_depth=15, min_child_weight=3;, score=0.969 total time= 1.9min\n",
      "[CV 2/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=1\n",
      "[15:11:37] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=1;, score=0.974 total time= 3.9min\n",
      "[CV 4/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1\n",
      "[15:16:29] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1;, score=0.990 total time= 3.3min\n",
      "[CV 7/10; 1/1] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=3\n",
      "[15:20:35] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10; 1/1] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=3;, score=0.959 total time= 3.7min\n",
      "[CV 3/10; 1/1] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.15, max_depth=4, min_child_weight=3\n",
      "[15:25:07] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10; 1/1] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.15, max_depth=4, min_child_weight=3;, score=0.974 total time= 2.9min\n",
      "[CV 10/10; 1/1] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.15, max_depth=4, min_child_weight=3\n",
      "[15:27:57] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10; 1/1] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.15, max_depth=4, min_child_weight=3;, score=0.948 total time=  43.9s\n",
      "[CV 3/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=3\n",
      "[15:28:44] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=3;, score=0.984 total time= 3.1min\n",
      "[CV 10/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=3\n",
      "[15:31:49] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=3;, score=0.959 total time=  48.0s\n",
      "[CV 5/10; 1/1] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.3, max_depth=12, min_child_weight=3\n",
      "[15:32:38] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10; 1/1] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.3, max_depth=12, min_child_weight=3;, score=0.979 total time= 1.5min\n",
      "[CV 8/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=1\n",
      "[15:34:30] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=1;, score=0.984 total time= 3.2min\n",
      "[CV 3/10; 1/1] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=10, min_child_weight=3\n",
      "[15:38:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10; 1/1] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=10, min_child_weight=3;, score=0.974 total time= 3.4min\n",
      "[CV 10/10; 1/1] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=10, min_child_weight=3\n",
      "[15:42:01] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10; 1/1] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=10, min_child_weight=3;, score=0.964 total time=  47.9s\n",
      "[CV 8/10; 1/1] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=1\n",
      "[15:42:51] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10; 1/1] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=1;, score=0.990 total time= 4.7min\n",
      "[CV 1/10; 1/1] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.05, max_depth=6, min_child_weight=3\n",
      "[15:48:47] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10; 1/1] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.05, max_depth=6, min_child_weight=3;, score=0.974 total time= 4.6min\n",
      "[CV 5/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.05, max_depth=12, min_child_weight=3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10; 1/1] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.2, max_depth=10, min_child_weight=7\n",
      "[14:30:43] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10; 1/1] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.2, max_depth=10, min_child_weight=7;, score=0.948 total time= 2.5min\n",
      "[CV 1/10; 1/1] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.3, max_depth=8, min_child_weight=3\n",
      "[14:33:52] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10; 1/1] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.3, max_depth=8, min_child_weight=3;, score=0.984 total time= 2.2min\n",
      "[CV 7/10; 1/1] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.15, max_depth=4, min_child_weight=3\n",
      "[14:36:33] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10; 1/1] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.15, max_depth=4, min_child_weight=3;, score=0.964 total time= 2.8min\n",
      "[CV 4/10; 1/1] START colsample_bytree=0.3, gamma=0.3, learning_rate=0.15, max_depth=6, min_child_weight=5\n",
      "[14:40:01] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10; 1/1] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.15, max_depth=6, min_child_weight=5;, score=0.974 total time= 1.9min\n",
      "[CV 6/10; 1/1] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=5, min_child_weight=3\n",
      "[14:42:20] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10; 1/1] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=5, min_child_weight=3;, score=0.964 total time= 1.9min\n",
      "[CV 9/10; 1/1] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=5, min_child_weight=3\n",
      "[14:44:16] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10; 1/1] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=5, min_child_weight=3;, score=0.964 total time=  31.4s\n",
      "[CV 2/10; 1/1] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.25, max_depth=6, min_child_weight=3\n",
      "[14:44:49] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10; 1/1] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.25, max_depth=6, min_child_weight=3;, score=0.979 total time= 3.6min\n",
      "[CV 6/10; 1/1] START colsample_bytree=0.7, gamma=0.3, learning_rate=0.15, max_depth=4, min_child_weight=3\n",
      "[14:49:25] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10; 1/1] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.15, max_depth=4, min_child_weight=3;, score=0.969 total time= 3.7min\n",
      "[CV 9/10; 1/1] START colsample_bytree=0.7, gamma=0.3, learning_rate=0.15, max_depth=4, min_child_weight=3\n",
      "[14:53:07] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10; 1/1] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.15, max_depth=4, min_child_weight=3;, score=0.974 total time=12.5min\n",
      "[CV 2/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=1\n",
      "[15:05:34] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=1;, score=0.974 total time= 2.9min\n",
      "[CV 1/10; 1/1] START colsample_bytree=0.3, gamma=0.4, learning_rate=0.25, max_depth=15, min_child_weight=3\n",
      "[15:09:11] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10; 1/1] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.25, max_depth=15, min_child_weight=3;, score=0.984 total time= 1.9min\n",
      "[CV 3/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=1\n",
      "[15:11:37] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=1;, score=0.969 total time= 3.8min\n",
      "[CV 10/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=1\n",
      "[15:15:26] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=1;, score=0.964 total time= 1.0min\n",
      "[CV 2/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1\n",
      "[15:16:29] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1;, score=0.974 total time= 3.3min\n",
      "[CV 5/10; 1/1] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=3\n",
      "[15:20:35] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10; 1/1] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=3;, score=0.979 total time= 3.7min\n",
      "[CV 2/10; 1/1] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.15, max_depth=4, min_child_weight=3\n",
      "[15:25:06] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10; 1/1] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.15, max_depth=4, min_child_weight=3;, score=0.974 total time= 2.9min\n",
      "[CV 8/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=3\n",
      "[15:28:45] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=3;, score=0.984 total time= 3.1min\n",
      "[CV 4/10; 1/1] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.3, max_depth=12, min_child_weight=3\n",
      "[15:32:38] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10; 1/1] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.3, max_depth=12, min_child_weight=3;, score=0.979 total time= 1.5min\n",
      "[CV 3/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=1\n",
      "[15:34:30] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=1;, score=0.979 total time= 3.2min\n",
      "[CV 1/10; 1/1] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=10, min_child_weight=3\n",
      "[15:38:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10; 1/1] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=10, min_child_weight=3;, score=0.984 total time= 3.5min\n",
      "[CV 4/10; 1/1] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=1\n",
      "[15:42:51] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10; 1/1] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=1;, score=0.984 total time= 4.7min\n",
      "[CV 7/10; 1/1] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.05, max_depth=6, min_child_weight=3\n",
      "[15:48:48] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10; 1/1] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.05, max_depth=6, min_child_weight=3;, score=0.964 total time= 4.6min\n",
      "[CV 10/10; 1/1] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.05, max_depth=6, min_child_weight=3\n",
      "[15:53:20] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10; 1/1] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.05, max_depth=6, min_child_weight=3;, score=0.953 total time= 1.2min\n",
      "[CV 4/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.05, max_depth=12, min_child_weight=3\n",
      "[15:54:35] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.05, max_depth=12, min_child_weight=3;, score=0.995 total time= 5.1min\n",
      "[CV 3/10; 1/1] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=3\n",
      "[16:00:58] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10; 1/1] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=3;, score=0.979 total time= 2.6min\n",
      "[CV 6/10; 1/1] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=10, min_child_weight=5\n",
      "[16:04:20] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10; 1/1] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=10, min_child_weight=5;, score=0.959 total time= 2.4min\n",
      "[CV 1/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=10, min_child_weight=3\n",
      "[CV 2/10; 1/1] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.2, max_depth=10, min_child_weight=7\n",
      "[14:30:43] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10; 1/1] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.2, max_depth=10, min_child_weight=7;, score=0.979 total time= 2.5min\n",
      "[CV 7/10; 1/1] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.3, max_depth=8, min_child_weight=3\n",
      "[14:33:52] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10; 1/1] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.3, max_depth=8, min_child_weight=3;, score=0.953 total time= 2.2min\n",
      "[CV 2/10; 1/1] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.15, max_depth=4, min_child_weight=3\n",
      "[14:36:33] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10; 1/1] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.15, max_depth=4, min_child_weight=3;, score=0.979 total time= 2.8min\n",
      "[CV 10/10; 1/1] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.15, max_depth=4, min_child_weight=3\n",
      "[14:39:18] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10; 1/1] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.15, max_depth=4, min_child_weight=3;, score=0.953 total time=  41.2s\n",
      "[CV 2/10; 1/1] START colsample_bytree=0.3, gamma=0.3, learning_rate=0.15, max_depth=6, min_child_weight=5\n",
      "[14:40:01] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10; 1/1] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.15, max_depth=6, min_child_weight=5;, score=0.974 total time= 1.9min\n",
      "[CV 5/10; 1/1] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=5, min_child_weight=3\n",
      "[14:42:20] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10; 1/1] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=5, min_child_weight=3;, score=0.974 total time= 2.0min\n",
      "[CV 6/10; 1/1] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.25, max_depth=6, min_child_weight=3\n",
      "[14:44:49] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10; 1/1] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.25, max_depth=6, min_child_weight=3;, score=0.959 total time= 3.6min\n",
      "[CV 9/10; 1/1] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.25, max_depth=6, min_child_weight=3\n",
      "[14:48:22] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10; 1/1] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.25, max_depth=6, min_child_weight=3;, score=0.969 total time= 1.0min\n",
      "[CV 3/10; 1/1] START colsample_bytree=0.7, gamma=0.3, learning_rate=0.15, max_depth=4, min_child_weight=3\n",
      "[14:49:25] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10; 1/1] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.15, max_depth=4, min_child_weight=3;, score=0.969 total time= 3.7min\n",
      "[CV 10/10; 1/1] START colsample_bytree=0.7, gamma=0.3, learning_rate=0.15, max_depth=4, min_child_weight=3\n",
      "[14:53:07] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10; 1/1] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.15, max_depth=4, min_child_weight=3;, score=0.953 total time=12.4min\n",
      "[CV 3/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=1\n",
      "[15:05:34] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=1;, score=0.969 total time= 2.9min\n",
      "[CV 10/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=1\n",
      "[15:08:27] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=1;, score=0.959 total time=  42.4s\n",
      "[CV 2/10; 1/1] START colsample_bytree=0.3, gamma=0.4, learning_rate=0.25, max_depth=15, min_child_weight=3\n",
      "[15:09:11] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10; 1/1] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.25, max_depth=15, min_child_weight=3;, score=0.974 total time= 1.9min\n",
      "[CV 4/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=1\n",
      "[15:11:37] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=1;, score=0.995 total time= 3.9min\n",
      "[CV 7/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1\n",
      "[15:16:29] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1;, score=0.964 total time= 3.3min\n",
      "[CV 8/10; 1/1] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=3\n",
      "[15:20:35] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10; 1/1] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=3;, score=0.990 total time= 3.7min\n",
      "[CV 4/10; 1/1] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.15, max_depth=4, min_child_weight=3\n",
      "[15:25:07] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10; 1/1] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.15, max_depth=4, min_child_weight=3;, score=0.990 total time= 2.9min\n",
      "[CV 2/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=3\n",
      "[15:28:45] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=3;, score=0.979 total time= 3.2min\n",
      "[CV 7/10; 1/1] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.3, max_depth=12, min_child_weight=3\n",
      "[15:32:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10; 1/1] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.3, max_depth=12, min_child_weight=3;, score=0.953 total time= 1.5min\n",
      "[CV 2/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=1\n",
      "[15:34:30] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=1;, score=0.974 total time= 3.2min\n",
      "[CV 2/10; 1/1] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=10, min_child_weight=3\n",
      "[15:38:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10; 1/1] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=10, min_child_weight=3;, score=0.979 total time= 3.5min\n",
      "[CV 2/10; 1/1] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=1\n",
      "[15:42:51] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10; 1/1] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=1;, score=0.974 total time= 4.7min\n",
      "[CV 10/10; 1/1] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=1\n",
      "[15:47:31] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10; 1/1] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=1;, score=0.959 total time= 1.2min\n",
      "[CV 2/10; 1/1] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.05, max_depth=6, min_child_weight=3\n",
      "[15:48:47] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10; 1/1] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.05, max_depth=6, min_child_weight=3;, score=0.974 total time= 4.6min\n",
      "[CV 1/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.05, max_depth=12, min_child_weight=3\n",
      "[15:54:35] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.05, max_depth=12, min_child_weight=3;, score=0.979 total time= 5.0min\n",
      "[CV 8/10; 1/1] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=3\n",
      "[16:00:58] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10; 1/1] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=3;, score=0.984 total time= 2.6min\n",
      "[CV 8/10; 1/1] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=10, min_child_weight=5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=1\n",
      "[15:05:38] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=1;, score=0.990 total time= 2.9min\n",
      "[CV 4/10; 1/1] START colsample_bytree=0.3, gamma=0.4, learning_rate=0.25, max_depth=15, min_child_weight=3\n",
      "[15:09:11] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10; 1/1] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.25, max_depth=15, min_child_weight=3;, score=0.990 total time= 1.9min\n",
      "[CV 7/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=1\n",
      "[15:11:37] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=1;, score=0.964 total time= 3.9min\n",
      "[CV 6/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1\n",
      "[15:16:29] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1;, score=0.959 total time= 3.3min\n",
      "[CV 10/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1\n",
      "[15:19:44] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1;, score=0.953 total time=  48.2s\n",
      "[CV 3/10; 1/1] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=3\n",
      "[15:20:35] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10; 1/1] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=3;, score=0.969 total time= 3.6min\n",
      "[CV 10/10; 1/1] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=3\n",
      "[15:24:10] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10; 1/1] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=3;, score=0.953 total time=  54.4s\n",
      "[CV 8/10; 1/1] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.15, max_depth=4, min_child_weight=3\n",
      "[15:25:07] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10; 1/1] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.15, max_depth=4, min_child_weight=3;, score=0.984 total time= 2.9min\n",
      "[CV 4/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=3\n",
      "[15:28:44] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=3;, score=0.995 total time= 3.1min\n",
      "[CV 6/10; 1/1] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.3, max_depth=12, min_child_weight=3\n",
      "[15:32:38] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10; 1/1] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.3, max_depth=12, min_child_weight=3;, score=0.969 total time= 1.4min\n",
      "[CV 9/10; 1/1] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.3, max_depth=12, min_child_weight=3\n",
      "[15:34:03] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10; 1/1] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.3, max_depth=12, min_child_weight=3;, score=0.964 total time=  23.4s\n",
      "[CV 4/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=1\n",
      "[15:34:30] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=1;, score=0.995 total time= 3.2min\n",
      "[CV 6/10; 1/1] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=10, min_child_weight=3\n",
      "[15:38:38] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10; 1/1] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=10, min_child_weight=3;, score=0.969 total time= 3.4min\n",
      "[CV 9/10; 1/1] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=10, min_child_weight=3\n",
      "[15:42:00] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10; 1/1] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=10, min_child_weight=3;, score=0.974 total time=  48.9s\n",
      "[CV 3/10; 1/1] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=1\n",
      "[15:42:51] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10; 1/1] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=1;, score=0.979 total time= 4.7min\n",
      "[CV 4/10; 1/1] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.05, max_depth=6, min_child_weight=3\n",
      "[15:48:47] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10; 1/1] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.05, max_depth=6, min_child_weight=3;, score=0.990 total time= 4.6min\n",
      "[CV 6/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.05, max_depth=12, min_child_weight=3\n",
      "[15:54:35] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.05, max_depth=12, min_child_weight=3;, score=0.964 total time= 4.9min\n",
      "[CV 9/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.05, max_depth=12, min_child_weight=3\n",
      "[15:59:29] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.05, max_depth=12, min_child_weight=3;, score=0.969 total time= 1.5min\n",
      "[CV 6/10; 1/1] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=3\n",
      "[16:00:58] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10; 1/1] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=3;, score=0.959 total time= 2.5min\n",
      "[CV 9/10; 1/1] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=3\n",
      "[16:03:30] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10; 1/1] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=3;, score=0.974 total time=  47.9s\n",
      "[CV 7/10; 1/1] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=10, min_child_weight=5\n",
      "[16:04:20] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10; 1/1] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=10, min_child_weight=5;, score=0.953 total time= 2.4min\n",
      "[CV 10/10; 1/1] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=10, min_child_weight=5\n",
      "[16:06:43] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10; 1/1] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=10, min_child_weight=5;, score=0.959 total time=  37.4s\n",
      "[CV 5/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=10, min_child_weight=3\n",
      "[16:07:24] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=10, min_child_weight=3;, score=0.979 total time= 2.4min\n",
      "[CV 6/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.25, max_depth=5, min_child_weight=5\n",
      "[16:10:21] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.25, max_depth=5, min_child_weight=5;, score=0.959 total time= 1.8min\n",
      "[CV 9/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.25, max_depth=5, min_child_weight=5\n",
      "[16:12:07] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.25, max_depth=5, min_child_weight=5;, score=0.964 total time=  29.2s\n",
      "[CV 8/10; 1/1] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.25, max_depth=8, min_child_weight=7\n",
      "[16:12:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10; 1/1] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.25, max_depth=8, min_child_weight=7;, score=0.974 total time= 2.1min\n",
      "[CV 9/10; 1/1] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.25, max_depth=8, min_child_weight=7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=1\n",
      "[15:05:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=1;, score=0.964 total time= 2.8min\n",
      "[CV 3/10; 1/1] START colsample_bytree=0.3, gamma=0.4, learning_rate=0.25, max_depth=15, min_child_weight=3\n",
      "[15:09:11] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10; 1/1] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.25, max_depth=15, min_child_weight=3;, score=0.974 total time= 1.8min\n",
      "[CV 10/10; 1/1] START colsample_bytree=0.3, gamma=0.4, learning_rate=0.25, max_depth=15, min_child_weight=3\n",
      "[15:11:01] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10; 1/1] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.25, max_depth=15, min_child_weight=3;, score=0.959 total time=  31.4s\n",
      "[CV 6/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=1\n",
      "[15:11:37] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=1;, score=0.959 total time= 3.8min\n",
      "[CV 9/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=1\n",
      "[15:15:25] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=1;, score=0.969 total time= 1.1min\n",
      "[CV 8/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1\n",
      "[15:16:29] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1;, score=0.990 total time= 3.3min\n",
      "[CV 9/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1\n",
      "[15:19:44] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1;, score=0.974 total time=  48.4s\n",
      "[CV 6/10; 1/1] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=3\n",
      "[15:20:35] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10; 1/1] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=3;, score=0.964 total time= 3.6min\n",
      "[CV 9/10; 1/1] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=3\n",
      "[15:24:10] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10; 1/1] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=3;, score=0.969 total time=  55.3s\n",
      "[CV 5/10; 1/1] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.15, max_depth=4, min_child_weight=3\n",
      "[15:25:07] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10; 1/1] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.15, max_depth=4, min_child_weight=3;, score=0.979 total time= 2.9min\n",
      "[CV 1/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=3\n",
      "[15:28:44] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=3;, score=0.984 total time= 3.2min\n",
      "[CV 2/10; 1/1] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.3, max_depth=12, min_child_weight=3\n",
      "[15:32:38] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10; 1/1] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.3, max_depth=12, min_child_weight=3;, score=0.974 total time= 1.5min\n",
      "[CV 6/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=1\n",
      "[15:34:30] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=1;, score=0.959 total time= 3.2min\n",
      "[CV 9/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=1\n",
      "[15:37:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=1;, score=0.964 total time=  55.5s\n",
      "[CV 7/10; 1/1] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=10, min_child_weight=3\n",
      "[15:38:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10; 1/1] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=10, min_child_weight=3;, score=0.959 total time= 3.4min\n",
      "[CV 1/10; 1/1] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=1\n",
      "[15:42:51] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10; 1/1] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=1;, score=0.979 total time= 4.7min\n",
      "[CV 8/10; 1/1] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.05, max_depth=6, min_child_weight=3\n",
      "[15:48:48] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10; 1/1] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.05, max_depth=6, min_child_weight=3;, score=0.990 total time= 4.6min\n",
      "[CV 7/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.05, max_depth=12, min_child_weight=3\n",
      "[15:54:35] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.05, max_depth=12, min_child_weight=3;, score=0.964 total time= 5.0min\n",
      "[CV 1/10; 1/1] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=3\n",
      "[16:00:58] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10; 1/1] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=3;, score=0.979 total time= 2.6min\n",
      "[CV 2/10; 1/1] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=10, min_child_weight=5\n",
      "[16:04:20] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10; 1/1] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=10, min_child_weight=5;, score=0.979 total time= 2.5min\n",
      "[CV 3/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=10, min_child_weight=3\n",
      "[16:07:23] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=10, min_child_weight=3;, score=0.984 total time= 2.3min\n",
      "[CV 9/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=10, min_child_weight=3\n",
      "[16:09:41] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=10, min_child_weight=3;, score=0.969 total time=  38.8s\n",
      "[CV 3/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.25, max_depth=5, min_child_weight=5\n",
      "[16:10:21] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.25, max_depth=5, min_child_weight=5;, score=0.974 total time= 1.8min\n",
      "[CV 1/10; 1/1] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.25, max_depth=8, min_child_weight=7\n",
      "[16:12:40] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10; 1/1] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.25, max_depth=8, min_child_weight=7;, score=0.990 total time= 2.2min\n",
      "[CV 6/10; 1/1] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=4, min_child_weight=5\n",
      "[16:15:21] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10; 1/1] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=4, min_child_weight=5;, score=0.953 total time= 4.1min\n",
      "[CV 9/10; 1/1] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=4, min_child_weight=5\n",
      "[16:19:28] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10; 1/1] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=4, min_child_weight=5;, score=0.969 total time= 1.1min\n",
      "[CV 8/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.1, max_depth=10, min_child_weight=3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=1\n",
      "[15:05:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=1;, score=0.969 total time= 2.9min\n",
      "[CV 8/10; 1/1] START colsample_bytree=0.3, gamma=0.4, learning_rate=0.25, max_depth=15, min_child_weight=3\n",
      "[15:09:11] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10; 1/1] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.25, max_depth=15, min_child_weight=3;, score=0.974 total time= 1.9min\n",
      "[CV 8/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=1\n",
      "[15:11:37] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=1;, score=0.984 total time= 3.9min\n",
      "[CV 5/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1\n",
      "[15:16:29] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1;, score=0.979 total time= 3.3min\n",
      "[CV 4/10; 1/1] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=3\n",
      "[15:20:35] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10; 1/1] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=3;, score=0.984 total time= 3.6min\n",
      "[CV 7/10; 1/1] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.15, max_depth=4, min_child_weight=3\n",
      "[15:25:07] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10; 1/1] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.15, max_depth=4, min_child_weight=3;, score=0.959 total time= 2.9min\n",
      "[CV 6/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=3\n",
      "[15:28:44] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=3;, score=0.969 total time= 3.1min\n",
      "[CV 9/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=3\n",
      "[15:31:48] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=3;, score=0.974 total time=  49.4s\n",
      "[CV 3/10; 1/1] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.3, max_depth=12, min_child_weight=3\n",
      "[15:32:38] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10; 1/1] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.3, max_depth=12, min_child_weight=3;, score=0.969 total time= 1.4min\n",
      "[CV 10/10; 1/1] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.3, max_depth=12, min_child_weight=3\n",
      "[15:34:03] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10; 1/1] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.3, max_depth=12, min_child_weight=3;, score=0.964 total time=  23.1s\n",
      "[CV 5/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=1\n",
      "[15:34:30] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=1;, score=0.979 total time= 3.2min\n",
      "[CV 10/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=1\n",
      "[15:37:40] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=1;, score=0.959 total time=  54.0s\n",
      "[CV 5/10; 1/1] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=10, min_child_weight=3\n",
      "[15:38:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10; 1/1] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=10, min_child_weight=3;, score=0.979 total time= 3.5min\n",
      "[CV 6/10; 1/1] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=1\n",
      "[15:42:51] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10; 1/1] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=1;, score=0.964 total time= 4.6min\n",
      "[CV 9/10; 1/1] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=1\n",
      "[15:47:29] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10; 1/1] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=1;, score=0.959 total time= 1.2min\n",
      "[CV 6/10; 1/1] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.05, max_depth=6, min_child_weight=3\n",
      "[15:48:47] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10; 1/1] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.05, max_depth=6, min_child_weight=3;, score=0.959 total time= 4.5min\n",
      "[CV 9/10; 1/1] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.05, max_depth=6, min_child_weight=3\n",
      "[15:53:18] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10; 1/1] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.05, max_depth=6, min_child_weight=3;, score=0.969 total time= 1.2min\n",
      "[CV 3/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.05, max_depth=12, min_child_weight=3\n",
      "[15:54:35] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.05, max_depth=12, min_child_weight=3;, score=0.974 total time= 5.0min\n",
      "[CV 10/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.05, max_depth=12, min_child_weight=3\n",
      "[15:59:32] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.05, max_depth=12, min_child_weight=3;, score=0.953 total time= 1.4min\n",
      "[CV 4/10; 1/1] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=3\n",
      "[16:00:58] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10; 1/1] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=3;, score=0.984 total time= 2.6min\n",
      "[CV 5/10; 1/1] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=10, min_child_weight=5\n",
      "[16:04:20] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10; 1/1] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=10, min_child_weight=5;, score=0.979 total time= 2.4min\n",
      "[CV 8/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=10, min_child_weight=3\n",
      "[16:07:24] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=10, min_child_weight=3;, score=0.979 total time= 2.3min\n",
      "[CV 1/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.25, max_depth=5, min_child_weight=5\n",
      "[16:10:21] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.25, max_depth=5, min_child_weight=5;, score=0.979 total time= 1.8min\n",
      "[CV 5/10; 1/1] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.25, max_depth=8, min_child_weight=7\n",
      "[16:12:40] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10; 1/1] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.25, max_depth=8, min_child_weight=7;, score=0.984 total time= 2.2min\n",
      "[CV 2/10; 1/1] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=4, min_child_weight=5\n",
      "[16:15:21] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10; 1/1] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=4, min_child_weight=5;, score=0.979 total time= 4.2min\n",
      "[CV 7/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.1, max_depth=10, min_child_weight=3\n",
      "[16:20:38] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.1, max_depth=10, min_child_weight=3;, score=0.964 total time= 3.9min\n",
      "[CV 1/10; 1/1] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=4, min_child_weight=7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=1\n",
      "[15:05:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=1;, score=0.969 total time= 2.9min\n",
      "[CV 5/10; 1/1] START colsample_bytree=0.3, gamma=0.4, learning_rate=0.25, max_depth=15, min_child_weight=3\n",
      "[15:09:11] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10; 1/1] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.25, max_depth=15, min_child_weight=3;, score=0.979 total time= 1.9min\n",
      "[CV 1/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=1\n",
      "[15:11:37] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=1;, score=0.974 total time= 3.9min\n",
      "[CV 3/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1\n",
      "[15:16:29] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1;, score=0.974 total time= 3.3min\n",
      "[CV 1/10; 1/1] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=3\n",
      "[15:20:35] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10; 1/1] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=3;, score=0.979 total time= 3.6min\n",
      "[CV 1/10; 1/1] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.15, max_depth=4, min_child_weight=3\n",
      "[15:25:06] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10; 1/1] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.15, max_depth=4, min_child_weight=3;, score=0.984 total time= 2.9min\n",
      "[CV 7/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=3\n",
      "[15:28:45] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=3;, score=0.959 total time= 3.1min\n",
      "[CV 8/10; 1/1] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.3, max_depth=12, min_child_weight=3\n",
      "[15:32:38] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10; 1/1] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.3, max_depth=12, min_child_weight=3;, score=0.979 total time= 1.5min\n",
      "[CV 1/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=1\n",
      "[15:34:30] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=1;, score=0.979 total time= 3.2min\n",
      "[CV 8/10; 1/1] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=10, min_child_weight=3\n",
      "[15:38:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10; 1/1] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=10, min_child_weight=3;, score=0.984 total time= 3.5min\n",
      "[CV 7/10; 1/1] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=1\n",
      "[15:42:51] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10; 1/1] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=1;, score=0.964 total time= 4.7min\n",
      "[CV 5/10; 1/1] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.05, max_depth=6, min_child_weight=3\n",
      "[15:48:47] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10; 1/1] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.05, max_depth=6, min_child_weight=3;, score=0.984 total time= 4.6min\n",
      "[CV 8/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.05, max_depth=12, min_child_weight=3\n",
      "[15:54:35] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.05, max_depth=12, min_child_weight=3;, score=0.990 total time= 5.1min\n",
      "[CV 7/10; 1/1] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=3\n",
      "[16:00:58] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10; 1/1] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=3;, score=0.964 total time= 2.6min\n",
      "[CV 4/10; 1/1] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=10, min_child_weight=5\n",
      "[16:04:20] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10; 1/1] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=10, min_child_weight=5;, score=0.990 total time= 2.4min\n",
      "[CV 2/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=10, min_child_weight=3\n",
      "[16:07:24] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=10, min_child_weight=3;, score=0.974 total time= 2.4min\n",
      "[CV 5/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.25, max_depth=5, min_child_weight=5\n",
      "[16:10:21] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.25, max_depth=5, min_child_weight=5;, score=0.974 total time= 1.8min\n",
      "[CV 10/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.25, max_depth=5, min_child_weight=5\n",
      "[16:12:08] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.25, max_depth=5, min_child_weight=5;, score=0.948 total time=  28.4s\n",
      "[CV 2/10; 1/1] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.25, max_depth=8, min_child_weight=7\n",
      "[16:12:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10; 1/1] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.25, max_depth=8, min_child_weight=7;, score=0.979 total time= 2.2min\n",
      "[CV 5/10; 1/1] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=4, min_child_weight=5\n",
      "[16:15:21] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10; 1/1] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=4, min_child_weight=5;, score=0.969 total time= 4.2min\n",
      "[CV 6/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.1, max_depth=10, min_child_weight=3\n",
      "[16:20:37] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.1, max_depth=10, min_child_weight=3;, score=0.964 total time= 3.8min\n",
      "[CV 9/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.1, max_depth=10, min_child_weight=3\n",
      "[16:24:24] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.1, max_depth=10, min_child_weight=3;, score=0.974 total time= 1.1min\n",
      "[CV 5/10; 1/1] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=4, min_child_weight=7\n",
      "[16:25:29] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10; 1/1] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=4, min_child_weight=7;, score=0.979 total time= 2.7min\n",
      "[CV 10/10; 1/1] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=4, min_child_weight=7\n",
      "[16:28:10] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10; 1/1] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=4, min_child_weight=7;, score=0.948 total time=  40.0s\n",
      "[CV 6/10; 1/1] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=5\n",
      "[16:28:53] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10; 1/1] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=5;, score=0.953 total time= 2.5min\n",
      "[CV 9/10; 1/1] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=5\n",
      "[16:31:25] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10; 1/1] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=5;, score=0.974 total time=  40.8s\n",
      "[CV 2/10; 1/1] START colsample_bytree=0.3, gamma=0.1, learning_rate=0.15, max_depth=15, min_child_weight=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=1\n",
      "[15:05:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=1;, score=0.964 total time= 2.9min\n",
      "[CV 6/10; 1/1] START colsample_bytree=0.3, gamma=0.4, learning_rate=0.25, max_depth=15, min_child_weight=3\n",
      "[15:09:11] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10; 1/1] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.25, max_depth=15, min_child_weight=3;, score=0.959 total time= 1.8min\n",
      "[CV 9/10; 1/1] START colsample_bytree=0.3, gamma=0.4, learning_rate=0.25, max_depth=15, min_child_weight=3\n",
      "[15:11:00] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10; 1/1] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.25, max_depth=15, min_child_weight=3;, score=0.969 total time=  32.4s\n",
      "[CV 5/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=1\n",
      "[15:11:37] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=1;, score=0.979 total time= 3.9min\n",
      "[CV 1/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1\n",
      "[15:16:29] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1;, score=0.974 total time= 3.3min\n",
      "[CV 2/10; 1/1] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=3\n",
      "[15:20:35] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10; 1/1] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=3;, score=0.974 total time= 3.6min\n",
      "[CV 6/10; 1/1] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.15, max_depth=4, min_child_weight=3\n",
      "[15:25:06] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10; 1/1] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.15, max_depth=4, min_child_weight=3;, score=0.964 total time= 2.8min\n",
      "[CV 9/10; 1/1] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.15, max_depth=4, min_child_weight=3\n",
      "[15:27:55] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10; 1/1] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.15, max_depth=4, min_child_weight=3;, score=0.974 total time=  46.2s\n",
      "[CV 5/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=3\n",
      "[15:28:44] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=3;, score=0.974 total time= 3.1min\n",
      "[CV 1/10; 1/1] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.3, max_depth=12, min_child_weight=3\n",
      "[15:32:38] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10; 1/1] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.3, max_depth=12, min_child_weight=3;, score=0.984 total time= 1.5min\n",
      "[CV 7/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=1\n",
      "[15:34:30] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.15, max_depth=10, min_child_weight=1;, score=0.964 total time= 3.2min\n",
      "[CV 4/10; 1/1] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=10, min_child_weight=3\n",
      "[15:38:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10; 1/1] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=10, min_child_weight=3;, score=0.995 total time= 3.5min\n",
      "[CV 5/10; 1/1] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=1\n",
      "[15:42:51] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10; 1/1] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=1;, score=0.979 total time= 4.7min\n",
      "[CV 3/10; 1/1] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.05, max_depth=6, min_child_weight=3\n",
      "[15:48:47] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10; 1/1] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.05, max_depth=6, min_child_weight=3;, score=0.969 total time= 4.6min\n",
      "[CV 2/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.05, max_depth=12, min_child_weight=3\n",
      "[15:54:35] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.05, max_depth=12, min_child_weight=3;, score=0.979 total time= 5.1min\n",
      "[CV 2/10; 1/1] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=3\n",
      "[16:00:58] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10; 1/1] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=3;, score=0.974 total time= 2.6min\n",
      "[CV 1/10; 1/1] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=10, min_child_weight=5\n",
      "[16:04:20] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10; 1/1] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=10, min_child_weight=5;, score=0.979 total time= 2.5min\n",
      "[CV 4/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=10, min_child_weight=3\n",
      "[16:07:24] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=10, min_child_weight=3;, score=0.995 total time= 2.4min\n",
      "[CV 4/10; 1/1] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.25, max_depth=5, min_child_weight=5\n",
      "[16:10:21] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10; 1/1] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.25, max_depth=5, min_child_weight=5;, score=0.984 total time= 1.8min\n",
      "[CV 4/10; 1/1] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.25, max_depth=8, min_child_weight=7\n",
      "[16:12:40] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10; 1/1] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.25, max_depth=8, min_child_weight=7;, score=0.990 total time= 2.2min\n",
      "[CV 4/10; 1/1] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=4, min_child_weight=5\n",
      "[16:15:22] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10; 1/1] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=4, min_child_weight=5;, score=0.990 total time= 4.2min\n",
      "[CV 2/10; 1/1] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.1, max_depth=10, min_child_weight=3\n",
      "[16:20:38] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10; 1/1] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.1, max_depth=10, min_child_weight=3;, score=0.979 total time= 3.9min\n",
      "[CV 3/10; 1/1] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=4, min_child_weight=7\n",
      "[16:25:29] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10; 1/1] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=4, min_child_weight=7;, score=0.974 total time= 2.7min\n",
      "[CV 1/10; 1/1] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=5\n",
      "[16:28:53] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10; 1/1] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=5;, score=0.974 total time= 2.6min\n",
      "[CV 7/10; 1/1] START colsample_bytree=0.3, gamma=0.1, learning_rate=0.15, max_depth=15, min_child_weight=1\n",
      "[16:32:10] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10; 1/1] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.15, max_depth=15, min_child_weight=1;, score=0.959 total time= 2.8min\n",
      "[CV 1/10; 1/1] START colsample_bytree=0.7, gamma=0.1, learning_rate=0.15, max_depth=8, min_child_weight=1\n",
      "[16:35:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10; 1/1] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.15, max_depth=8, min_child_weight=1;, score=0.974 total time= 5.1min\n",
      "[CV 2/10; 1/1] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.2, max_depth=6, min_child_weight=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yash/opt/anaconda3/envs/Om_sai_ram/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:53:18] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      "Best Parameters Found\n",
      "OrderedDict([('colsample_bytree', 0.5), ('gamma', 0.2), ('learning_rate', 0.15), ('max_depth', 10), ('min_child_weight', 3)])\n",
      "[17:53:42] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Xgboost Accuracy\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'chi2_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 129>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m Xgboost_accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXgboost Accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 129\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mchi2_accuracy\u001b[49m) \u001b[38;5;66;03m#0.9585492227979274, 0.6621621621621622\u001b[39;00m\n\u001b[1;32m    131\u001b[0m perf_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCell Type\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecall\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNegative Predictive Value\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpecificity\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1-score\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    132\u001b[0m perf_anova  \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns \u001b[38;5;241m=\u001b[39m perf_cols)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'chi2_accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "def precision_MC(y_true, y_pred):\n",
    "    TP = np.diag(confusion_matrix(y_true, y_pred))\n",
    "    FP = confusion_matrix(y_true, y_pred).sum(axis=1) - np.diag(confusion_matrix(y_true, y_pred))\n",
    "    FP = FP.astype(float)\n",
    "    TP = TP.astype(float)\n",
    "    precision = TP/(TP+FP) * 100\n",
    "    return precision\n",
    "\n",
    "def recall_MC(y_true, y_pred):\n",
    "    TP = np.diag(confusion_matrix(y_true, y_pred))\n",
    "    FN = confusion_matrix(y_true, y_pred).sum(axis=0) - np.diag(confusion_matrix(y_true, y_pred))\n",
    "    FN = FN.astype(float)\n",
    "    TP = TP.astype(float)\n",
    "    recall =  TP/(TP+FN) * 100\n",
    "    return recall\n",
    "\n",
    "def accuracy_MC(y_true, y_pred):\n",
    "    FP = confusion_matrix(y_true, y_pred).sum(axis=1) - np.diag(confusion_matrix(y_true, y_pred))  \n",
    "    FN = confusion_matrix(y_true, y_pred).sum(axis=0) - np.diag(confusion_matrix(y_true, y_pred))\n",
    "    TP = np.diag(confusion_matrix(y_true, y_pred))\n",
    "    TP = TP.astype(float)\n",
    "    TN = confusion_matrix(y_true, y_pred).sum() - (FP + FN + TP)\n",
    "    FP = FP.astype(float)\n",
    "    FN = FN.astype(float)\n",
    "    TN = TN.astype(float)\n",
    "    accuracy = (TP+TN)/(TP+FP+FN+TN) * 100\n",
    "    return accuracy\n",
    "\n",
    "def npval_MC(y_true, y_pred): \n",
    "    FN = confusion_matrix(y_true, y_pred).sum(axis=0) - np.diag(confusion_matrix(y_true, y_pred))\n",
    "    FN = FN.astype(float)\n",
    "    TP = np.diag(confusion_matrix(y_true, y_pred))\n",
    "    TP = TP.astype(float)\n",
    "    FP = confusion_matrix(y_true, y_pred).sum(axis=1) - np.diag(confusion_matrix(y_true, y_pred)) \n",
    "    FP = FP.astype(float)\n",
    "    TN = confusion_matrix(y_true, y_pred).sum() - (FP + FN + TP)\n",
    "    TN = TN.astype(float)\n",
    "    npv = TN/(TN+FN) * 100\n",
    "    return npv\n",
    "\n",
    "def specificity_MC(y_true, y_pred): \n",
    "    FP = confusion_matrix(y_true, y_pred).sum(axis=1) - np.diag(confusion_matrix(y_true, y_pred)) \n",
    "    FP = FP.astype(float)\n",
    "    FN = confusion_matrix(y_true, y_pred).sum(axis=0) - np.diag(confusion_matrix(y_true, y_pred))\n",
    "    FN = FN.astype(float)\n",
    "    TP = np.diag(confusion_matrix(y_true, y_pred))\n",
    "    TP = TP.astype(float)\n",
    "    TN = confusion_matrix(y_true, y_pred).sum() - (FP + FN + TP)\n",
    "    TN = TN.astype(float)\n",
    "    spec = TN/(TN+FP)  * 100\n",
    "    return spec\n",
    "\n",
    "\n",
    "def plot_ROC_curve_MC(y_true, y_pred, FSName):\n",
    "    n_classes = len(np.unique(y_true))\n",
    "    y_true = label_binarize(y_true, classes=np.arange(n_classes))\n",
    "    #y_pred = label_binarize(y_pred, classes=np.arange(n_classes))\n",
    "    \n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_pred[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        \n",
    "    # First aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "    \n",
    "    # Plot all ROC curves\n",
    "    plt.figure()\n",
    "    #colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\"])\n",
    "    for i in range(n_classes):\n",
    "        plt.plot(\n",
    "            fpr[i],\n",
    "            tpr[i],\n",
    "            label=\"ROC curve of class {0} (area = {1:0.4f})\".format(i, roc_auc[i]),\n",
    "        )\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], \"k--\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curve of \" + str(FSName))\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    path = \"ROC_\"+ str(FSName)\n",
    "    plt.savefig(f'{path}.png')\n",
    "\n",
    "#Bayesian Search\n",
    "bayesian_search = BayesSearchCV(\n",
    "        classifier,\n",
    "        {\n",
    "            'learning_rate'    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n",
    "            'max_depth'        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    "             'min_child_weight' : [ 1, 3, 5, 7 ],\n",
    "             'gamma'            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    "             'colsample_bytree' : [ 0.3, 0.4, 0.5 , 0.7 ]\n",
    "            #'max_leaf_nodes':Integer(0,prior='log-uniform'),\n",
    "            #'min_samples_leaf':Real(0.1,0.5,prior='uniform'),\n",
    "            #'min_samples_split':Real(0.1,1,prior='uniform')\n",
    "        },\n",
    "        n_iter=50,scoring='accuracy',n_jobs = -1, verbose = 10,\n",
    "        random_state=0, cv=10\n",
    "    )\n",
    "#grid_search = GridSearchCV(SVC(), tuned_params, cv=10, scoring='accuracy',n_jobs = -1, verbose = 10)\n",
    "bayesian_search.fit(X, y)\n",
    "bayesian_search.best_params_\n",
    "print(\"\")\n",
    "print(\"Best Parameters Found\")\n",
    "print(bayesian_search.best_params_) \n",
    "clf = xgb.XGBClassifier(learning_rate = bayesian_search.best_params_['learning_rate'], max_depth = bayesian_search.best_params_['max_depth'], min_child_weight= bayesian_search.best_params_['min_child_weight'],\n",
    "      gamma= bayesian_search.best_params_['gamma'], colsample_bytree= bayesian_search.best_params_['colsample_bytree'], use_label_encoder=False)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, stratify=y)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "X_train.shape\n",
    "X_test.shape \n",
    "Xgboost_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Xgboost Accuracy\")\n",
    "print(Xgboost_accuracy) #0.9585492227979274, 0.6621621621621622\n",
    "\n",
    "perf_cols = [\"Cell Type\", \"Accuracy%\",\"Precision%\",\"Recall%\",\"Negative Predictive Value%\",\"Specificity%\",\"F1-score%\"]\n",
    "perf_anova  = pd.DataFrame(columns = perf_cols)\n",
    "label = np.unique(y.tolist())\n",
    "class_lbl = [int(i) for i in label] \n",
    "class_lbl = ['CellType ' + str(s) for s in class_lbl]\n",
    "\n",
    "pre_chi2 = precision_MC(y_test,y_pred)\n",
    "rec_chi2 = recall_MC(y_test,y_pred)\n",
    "acc_chi2 = accuracy_MC(y_test,y_pred)\n",
    "npv_chi2 = npval_MC(y_test,y_pred)\n",
    "spe_chi2 = specificity_MC(y_test,y_pred)\n",
    "f1_chi2 = 2* (pre_chi2 * rec_chi2)/(pre_chi2 + rec_chi2)\n",
    "\n",
    "print(\"XGBoost MultiClass\")\n",
    "print(pre_chi2)\n",
    "print(rec_chi2)\n",
    "print(acc_chi2)\n",
    "print(npv_chi2)\n",
    "print(spe_chi2)\n",
    "print(f1_chi2)\n",
    "\n",
    "perf_chi2['Cell Type'] = class_lbl\n",
    "perf_chi2['Precision%'] = pre_chi2.tolist()\n",
    "perf_chi2['Accuracy%'] =  acc_chi2.tolist()\n",
    "perf_chi2['Recall%']  = rec_chi2.tolist()\n",
    "perf_chi2['Negative Predictive Value%'] = npv_chi2.tolist()\n",
    "perf_chi2['Specificity%'] = spe_chi2.tolist()\n",
    "perf_chi2['F1-score%'] = f1_chi2.tolist()\n",
    "\n",
    "perf_chi2.to_csv('xgboosPerformanceMetrics.csv', index = False)\n",
    "\n",
    "#Plot ROC curve for OneVsRest + Chi2\n",
    "#y_score_chi2 = classifier.fit(X_train_chi2, y_train_chi2).decision_function(X_test_chi2)\n",
    "\n",
    "n_classes = len(np.unique(y_test))\n",
    "y_pred_chi = label_binarize(y_pred, classes=np.arange(n_classes))\n",
    "\n",
    "plot_ROC_curve_MC(y_test, y_pred_chi, \"Chi2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4325a6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9740932642487047\n"
     ]
    }
   ],
   "source": [
    "print(Xgboost_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "953fb9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fh/mtkq58kd5ks3szv1j095_fbc0000gp/T/ipykernel_80203/3533521258.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall =  TP/(TP+FN) * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost MultiClass\n",
      "[ 96.875      100.          90.625       92.85714286  94.44444444\n",
      " 100.         100.          90.47619048  97.43589744 100.\n",
      "  75.         100.         100.           0.        ]\n",
      "[ 96.875       96.67896679  98.30508475 100.          97.14285714\n",
      "  97.26027397 100.         100.         100.         100.\n",
      " 100.         100.          66.66666667          nan]\n",
      "[ 99.65457686  98.44559585  98.791019    99.82728843  99.48186528\n",
      "  99.65457686 100.          99.65457686  99.82728843 100.\n",
      "  99.82728843 100.          99.82728843  99.82728843]\n",
      "[ 99.81718464  97.16088328  99.80582524 100.          99.81583794\n",
      "  99.60629921 100.         100.         100.         100.\n",
      " 100.         100.          99.82668977 100.        ]\n",
      "[ 99.81718464 100.          98.84615385  99.82332155  99.63235294\n",
      " 100.         100.          99.64285714  99.81515712 100.\n",
      "  99.82638889 100.         100.          99.82728843]\n",
      "[ 96.875       98.31144465  94.30894309  96.2962963   95.77464789\n",
      "  98.61111111 100.          95.          98.7012987  100.\n",
      "  85.71428571 100.          80.                  nan]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "perf_cols = [\"Cell Type\", \"Accuracy%\",\"Precision%\",\"Recall%\",\"Negative Predictive Value%\",\"Specificity%\",\"F1-score%\"]\n",
    "perf  = pd.DataFrame(columns = perf_cols)\n",
    "label = np.unique(y.tolist())\n",
    "class_lbl = [int(i) for i in label] \n",
    "class_lbl = ['CellType ' + str(s) for s in class_lbl]\n",
    "\n",
    "pre_chi2 = precision_MC(y_test,y_pred)\n",
    "rec_chi2 = recall_MC(y_test,y_pred)\n",
    "acc_chi2 = accuracy_MC(y_test,y_pred)\n",
    "npv_chi2 = npval_MC(y_test,y_pred)\n",
    "spe_chi2 = specificity_MC(y_test,y_pred)\n",
    "f1_chi2 = 2* (pre_chi2 * rec_chi2)/(pre_chi2 + rec_chi2)\n",
    "\n",
    "print(\"XGBoost MultiClass\")\n",
    "print(pre_chi2)\n",
    "print(rec_chi2)\n",
    "print(acc_chi2)\n",
    "print(npv_chi2)\n",
    "print(spe_chi2)\n",
    "print(f1_chi2)\n",
    "\n",
    "perf['Cell Type'] = class_lbl\n",
    "perf['Precision%'] = pre_chi2.tolist()\n",
    "perf['Accuracy%'] =  acc_chi2.tolist()\n",
    "perf['Recall%']  = rec_chi2.tolist()\n",
    "perf['Negative Predictive Value%'] = npv_chi2.tolist()\n",
    "perf['Specificity%'] = spe_chi2.tolist()\n",
    "perf['F1-score%'] = f1_chi2.tolist()\n",
    "\n",
    "perf.to_csv('XgboostPerformanceMetrics.csv', index = False)\n",
    "\n",
    "#Plot ROC curve for OneVsRest + Chi2\n",
    "#y_score_chi2 = classifier.fit(X_train_chi2, y_train_chi2).decision_function(X_test_chi2)\n",
    "\n",
    "n_classes = len(np.unique(y_test))\n",
    "y_pred_chi = label_binarize(y_pred, classes=np.arange(n_classes))\n",
    "\n",
    "plot_ROC_curve_MC(y_test, y_pred_chi, \"XGBoost_\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1288147",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
